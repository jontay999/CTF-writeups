{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b4d19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tensorize(s : str) -> torch.Tensor:\n",
    "  return torch.Tensor([(1 if (ch >> i) & 1 == 1 else -1) for ch in list(map(ord, s)) for i in range(8)])\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "  def __init__(self, in_dimension, mid_dimension, out_dimension=1):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.layer1 = torch.nn.Linear(in_dimension, mid_dimension)\n",
    "    self.layer2 = torch.nn.Linear(mid_dimension, out_dimension)\n",
    "\n",
    "  def step_activation(self, x : torch.Tensor) -> torch.Tensor:\n",
    "    x[x <= 0] = -1\n",
    "    x[x >  0] = 1\n",
    "    return x\n",
    "\n",
    "  def forward(self, x : torch.Tensor) -> int:\n",
    "    x = self.layer1(x)\n",
    "    x = self.step_activation(x)\n",
    "    x = self.layer2(x)\n",
    "    res = int(x)\n",
    "    x = self.step_activation(x)\n",
    "#     print(x)\n",
    "#     return int(x)\n",
    "    return x, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "784dc27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = 'grey{' + 'a'* 14 + '}'\n",
    "in_data = tensorize(guess)\n",
    "in_dim\t= len(in_data)\n",
    "\n",
    "model = NeuralNetwork(in_dim, 1280)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37276f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.], grad_fn=<IndexPutBackward0>), -1415)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42a9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensorize(guess)\n",
    "preds = model(tensor)\n",
    "target = torch.Tensor([1.])\n",
    "# if(bool(preds[0] == -1)): preds[0] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aa138b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "sM\n",
      "sM0\n",
      "sM02\n",
      "sM02T\n",
      "sM02T_\n",
      "sM02T_m\n",
      "sM02T_mA\n",
      "sM02T_mAc\n",
      "sM02T_mAch\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alphabet = list(string.printable)\n",
    "best = (-20000,-20000)\n",
    "arr = []\n",
    "flag = ''\n",
    "length = 23\n",
    "for j in range(10):\n",
    "    for i in alphabet:\n",
    "        guess = 'grey{' + flag + i +  'a'* (length - len(flag)) + '}'\n",
    "#         assert len(guess) == 40\n",
    "        tensor = tensorize(guess)\n",
    "        preds = model(tensor)\n",
    "        arr.append((preds[1], i))\n",
    "    arr = sorted(arr, reverse=True)[:6]\n",
    "    flag += arr[0][1]\n",
    "    print(flag)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abc3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1d9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8cc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d276e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b599b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2995\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "output = loss(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b975b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m output\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 2\u001b[0m new_guess \u001b[38;5;241m=\u001b[39m in_data \u001b[38;5;241m-\u001b[39m \u001b[43min_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m \u001b[38;5;66;03m# 100 is our 'learning rate'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m new_np \u001b[38;5;241m=\u001b[39m new_guess\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "output.backward()\n",
    "new_guess = in_data - in_data.grad * 100 # 100 is our 'learning rate'\n",
    "new_np = new_guess.detach().numpy().clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9999):\n",
    "    \n",
    "    targetstr = '14caca6f19fe8281d6d6eae7d1f81b11'\n",
    "    targetarr = [-2*(-1)**int(i) for i in f'{int(targetstr, 16):0128b}']\n",
    "    target = torch.Tensor(targetarr)\n",
    "    \n",
    "    img_tensor.requires_grad = True\n",
    "    img_tensor.grad = None\n",
    "        \n",
    "    save_image(img_tensor, 'whichlee_test.png')\n",
    "    h = hash(model, get_img_tensor('whichlee_test.png'), hashing_matrix)\n",
    "    if h == targetstr:\n",
    "        print(f'Win on iteration {i}')\n",
    "        break\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    foo = torch.matmul(model(img_tensor), hashing_matrix).flatten()\n",
    "    output = loss(foo, target)\n",
    "    output.backward()\n",
    "\n",
    "    img_tensor = img_tensor - img_tensor.grad * 100\n",
    "    arr = img_tensor.detach().numpy()\n",
    "    img_tensor = torch.Tensor(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
